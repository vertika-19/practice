{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/ace/vertika/test/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 0 1 ... 7 6 9]\n"
     ]
    }
   ],
   "source": [
    "train_x = data.values[:,1:]\n",
    "train_y = data.values[:,0]\n",
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29399\n"
     ]
    }
   ],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "print(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29399, 784)\n",
      "29399\n",
      "(12601, 784)\n",
      "(29399,)\n",
      "(12601,)\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x = train_x[:split_size, : ], train_x[split_size: , :]\n",
    "print(train_x.shape)\n",
    "print(len(train_x))\n",
    "print(val_x.shape)\n",
    "\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]\n",
    "print(train_y.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv( \"/home/ace/vertika/test/test.csv\"  ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "\n",
    "# set remaining variables\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden': <tf.Variable 'Variable:0' shape=(784, 50) dtype=float32_ref>,\n",
       " 'output': <tf.Variable 'Variable_1:0' shape=(50, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# number of neurons in each layer\n",
    "input_num_units = 28*28\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "# define placeholders\n",
    "x = tf.placeholder(tf.float32, [None, input_num_units])\n",
    "y = tf.placeholder(tf.float32, [None, output_num_units])\n",
    "\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_num_units, output_num_units], seed=seed))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([hidden_num_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))\n",
    "}\n",
    "\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 50), dtype=float32)\n",
      "Tensor(\"BiasAdd_1:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /home/ace/.ace_env2/local/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "h_layer = tf.nn.bias_add( tf.matmul( x, weights['hidden'] ), biases['hidden'] )\n",
    "h_layer = tf.nn.relu(h_layer)\n",
    "print(h_layer)\n",
    "\n",
    "\"\"\"\n",
    "out_layer = tf.contrib.layers.fully_connected(inputs=h_layer, num_outputs=output_num_units, activation_fn=tf.nn.relu, biases_initializer=tf.zeros_initializer() )\n",
    "print(out_layer)\n",
    "\n",
    "out_layer = tf.layers.batch_normalization(out_layer)\n",
    "\n",
    "\"\"\"\n",
    "out_layer = tf.nn.bias_add( tf.matmul( h_layer, weights['output']) , biases['output'] )\n",
    "print(out_layer)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits= out_layer, labels=y))\n",
    "print(cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot\n",
    "\n",
    "def preproc(unclean_batch_x):\n",
    "    \"\"\"Convert values to range 0-1\"\"\"\n",
    "    temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    "    \n",
    "    return temp_batch\n",
    "\n",
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "  #  print(\"Batch mask len:\" + str(len(batch_mask)))\n",
    "    #print(batch_mask)\n",
    "    \n",
    "    batch_x = train_x[batch_mask]\n",
    "   # print(\"Batch_x.shape\")\n",
    "    #print(batch_x.shape)\n",
    "\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    if dataset_name == 'train':\n",
    "        batch_y = train_y[batch_mask]\n",
    "        batch_y = dense_to_one_hot(batch_y)\n",
    "     #   print( \"Shape of batch_y\")\n",
    "      #  print(batch_y.shape)\n",
    "        \n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 4.24516\n",
      "Epoch: 2 cost = 2.09980\n",
      "Training completed\n",
      "Validation Accuracy:\n",
      "0.7348623\n",
      "Tensor(\"ArgMax_2:0\", shape=(?,), dtype=int64)\n",
      "len of pred:28000\n",
      "File written\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = len(train_x)/batch_size\n",
    "        #print(\"total no of batches: \" + str(total_batch))\n",
    "        for bt in range(total_batch):\n",
    "            batch_x, batch_y = batch_creator( batch_size, len(train_x), 'train')\n",
    "            _, c = sess.run( [optimizer, cost] ,  feed_dict = { x:batch_x, y: batch_y } )\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "            \n",
    "        print \"Epoch:\", (ep+1), \"cost =\", \"{:.5f}\".format(avg_cost)\n",
    "    \n",
    "    print(\"Training completed\")    \n",
    "    \n",
    "    pred_temp = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "    \n",
    "    print ( \"Validation Accuracy:\" )\n",
    "    print( accuracy.eval({x: val_x, y: dense_to_one_hot(val_y)}) )\n",
    "\n",
    "    predict = tf.argmax(out_layer, 1)\n",
    "    print(predict)\n",
    "    pred = predict.eval({x: test_x})\n",
    "    \n",
    "    print(\"len of pred:\" + str(len(pred)))\n",
    "    \n",
    "    outFile = open(\"/home/ace/vertika/test/out.csv\", \"w\")\n",
    "    outFile.write(\"ImageId,Label\\n\")\n",
    "    for i in range( len(pred)):\n",
    "        outFile.write( str(i+1) + \",\" + str(pred[i]) + \"\\n\")\n",
    "        \n",
    "    print(\"File written\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace_env2",
   "language": "python",
   "name": "ace_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
